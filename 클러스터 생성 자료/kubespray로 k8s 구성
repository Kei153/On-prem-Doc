** 클라우드는 베스쳔을 따로 쓰기 때문에 같은 vnet 환경에 vm 설치하여 쓰면 된다**

**로컬의 가상머신은 같은 네트워크 대역으로 묶을 수 잇다.(bridge 모드)**

1. 먼저 가상머신을 구성한다. 내 컴퓨터 환경은 맥os여서 호환 잘 되는 UTM을 설치하여 구성 하였다.
  UTM은 가상머신 만들 이미지가 필요하기 때문에 k8s를 지원하는 우분투 이미지를 다운 받는다.

  - UTM 설치
    brew install --cask utm
  - 우분투 이미지 다운로드 (내 로컬 컴퓨터 os에 맞는 이미지 다운하기))
	맥북용 우분투 이미지 : https://ubuntu.com/download/server/arm
    https://releases.ubuntu.com/22.04/ (amd)
    
    
🪛 1단계: 새 가상머신 만들기
UTM 실행 > 상단 메뉴에서 + 버튼 클릭 (새 가상 머신 만들기)
"Virtualize" 선택
운영 체제: "Linux" 선택
부트 이미지 선택(Boot ISO Image): '탐색' 버튼 누르고 다운받은 ubuntu-22.04-live-server-amd64.iso 선택
메모리 - 4기가 CPU - 2core Storage - 30Gib 공유 폴더  - 건너뛰기 (default)
Summary 에서 이름 정하고 저장

2단계: 가상머신 구성하기
  vm 세팅 전 네트워크 구성부터 한다. 전원 켜기 전 vm을 선택 후, 마우스 오른쪽 버튼을 눌러 'edit' 메뉴를 클릭한다.
  그 다음 뜨는 화면의 왼쪽 메뉴 중 Devices > 네트워크 를 선택한 다음 설정을 수정한다
	Network Mode : Bridged(Advanced)
	Bridged Interace : en0 (보통 en0 이 무선, en1 이 랜선)
	나머지는 상동
	후에 저장
  내 로컬 pc의 정보 알아내기 : 터미널에서 ifconfig 명령어 > en0 부분 정보 찾아서 inet 에 적힌 내 내부 ip 알아내기
 
3단계 : 만든 가상머신 켜기. 켜면 부팅 화면 나옴
  - 적당히 선택한다. 영어 등등.. 업뎃은 나중에 등으로
  - ubuntu server로 선택하고 설치. 디폴트로 continue하며 skip 하다가 network configuration 에서 커스텀 한다.
	'enp0s1 eth -' 이부분 선택(엔터) > 작은 메뉴창이 뜨면, 선택지 중 Edit IPv4 선택 > IPv4 Method 에서 Manual 선택
	구성 메뉴에서 나의 로컬 ip에 맞춰 작성한다. (나의 경우는 inet 10.10.110.52)

	(ex)
	항목	값	설명
	Subnet	10.10.110.0/24	서브넷 대역대
	Address	10.10.110.100	VM에 지정할 IP (로컬과 같은 대역)
	Gateway	10.10.110.1	보통 공유기 주소 (Mac에서 netstat -rn으로 확인 가능)
	Name servers	8.8.8.8,1.1.1.1	공용 DNS
	Search domains	(비워도 OK)	사용 안 해도 됨


  - mirror configuration 기다리고 다 끝나명 다음
  - 나머지는 그냥 정해진 대로.. 마지막 profile configuration 만 잘 설정
  - 그 뒤 나오는 ssh configuration  잘 설정.(install openssh server 체크)
  - featured server snaps 는 건너뛰기
  - install complete! 될 때가지 기다리고 다 되면 reboot
  - reboot하고 로그인 화면 안나오고 커서만 깜박이면 우측 상단에서 두번째에 위치한 Drive image options 에서 
  꺼내기를 누르고 Linux 2 옆에 위치한 Restarts the VM 을 눌러 재부팅하면 정상적으로 실행이 된다.
  (출처: https://ssunw.tistory.com/entry/M1-mac-가상환경에-Linux-설치하기UTM-Ubuntu [ssunw:티스토리])


정상적인 실행을 확인하면 내 로컬 터미널, 혹은 vm 에서 각자의 ip를 가지고 ping test 해본다.


-------

--------------------------------------------------------------------------

** 클러스터 구성 **

1. 먼저 내 로컬 PC에서 비번없이 ssh만으로 접속 가능하게 키 복사/저장 작업
  - 내 로컬에서 키를 만든다. (저장 경로는 ~/.ssh/id_rsa 로 함)
    명령어 : ssh-keygen -t rsa -b 4096 (password 없이 만듬)
	비공개키 권한 확인
	chmod 600 ~/.ssh/id_rsa \
        chmod 700 ~/.ssh
	chmod 600 ~/.ssh/authorized_keys

    만들어진 키 중 pub키를 접근 할 가상 머신에 복사
    명령어 : ssh-copy-id -i ~/.ssh/id_rsa.pub <user>@<nodeIP>
    처음 한 번은 비밀번호를 묻습니다 (정상)
    성공하면 복사한 각 노드의 ~/.ssh/authorized_keys 에 공개키가 자동 추가됨
    접속 테스트 : ssh <user>@<nodeIP>

2. 마스터 노드로 정할 서버에 접속해서 k8s 구성 준비
  - 마스터에서 노드로의 비번 없는 ssh 접속을 위해 1번 과정 반복 (마스터에서 만든 키를 마스터와 노드에 다 키 복사)
	명령어 : ssh-copy-id -i ~/.ssh/id_rsa.pub kei@<마스터,노드IP들>

3. ansible 공식 홈페이지 참조 :  https://kubespray.io/#/docs/ansible/ansible (ansible 설치 참조)
  - - 먼저 kubespray 패키지 다운로드 : git clone https://github.com/kubernetes-sigs/kubespray.git
	-  ~kubespray 생긴거 확인
	- kubespray 디렉토리에서 작업 
	- 명령어 : sudo apt install python3.10-venv (가상화 환경에서 kubespray 설치 위해)

4. ansible 문서에 쉘 세션 실행. 마지막 ‘pip install -U -r requirements.txt’ 까지 설치.
    - # sample 디렉토리를 기준으로 실제로 작업할 폴더를 복사한다
		: project_name=<이름 정하기>
		: cp -rfp inventory/sample inventory/${project_name}
    - 필요한 설정 값들 해당 문서 편집기로 작성
		: cd inventory/${project-name}/group_vars/k8s_cluster/addons.yaml
			- # helm 사용
				helm_enabled: true
				metrics_server_enabled: true

		: cd inventory/${project-name}/group_vars/k8s_cluster/k8s-cluster.yml
			- (…)
			- kube_proxy_strict_arp: true
			- (…)
			- auto_renew_certificates: true

		: inventory/${project-name}/inventory.ini
			[all]
			master ansible_host=10.0.2.4 ip=10.0.2.4 ansible_user=laonpeople
			worker ansible_host=10.0.2.5 ip=10.0.2.5 ansible_user=laonpeople

			[kube_control_plane]
			master

			[etcd:children]
			kube_control_plane

			[kube_node]
			worker

5. 설치
- ansible-playbook -i inventory/${project_name}/inventory.ini --become --become-user=root cluster.yml -K
			(--become --become-user=root 는 ansible문서 에서 become 검색하면 나옴. root로 설치 한다는 말임. -K는 암호랑 암튼 실행?)

6. 설치 후, kubespray 가상화 로그 아웃 하기 python-venv 
		명령어 : deactivate

7. ‘root’ 권한으로 실행 : kubectl get no 




** kube config 파일 있는 위치 : 가장 상위 경로에서 명령어 ‘ls’ > cd root/.kube/config **


-------------------------------------------------------------------------------------------

** 내 로컬에서 cloud server 로 구성한 k8s마스터노드 접속하기! **
** 사전에 public에 bastion server가 있어야 한다. **

	1. 먼저 bastion에서 마스터로 접속 되는지 확인
		명령어 : nc -zv <마스터 노드 ip> 6443 
		성공하면 

2. 마스터 노드에 있는 config 파일을 로컬로 가져온다
3. 가져온 config 파일을 ~/.kube/에 위치 시킨다



2. Bastion 서버 이용
	- 명령어 : ssh -i ./<bastion 서버 pem 키> -L 6443:10.0.2.4:6443 laonpeople@<bastion publicIP>
	- 위의 명령어 친 상태에서 내 컨피그 파일 위치 가지고 kubectl 접속
	-  명령어 : kubectl --kubeconfig ~/.kube/<config파일명> get nodes 
	(config 파일 서버 주소 = server: https://127.0.0.1:6443)

2. 오픈렌즈 이용
	- 계속 터미널 켜면 불편하다. 명령어로 해결한다.
		명령어 : ssh -N -i ./kei-test-bastion-vm_key.pem -L 6443:10.0.2.4:6443 laonpeople@<bastion-ip> &
open /Applications/OpenLens.app
	
**  만약 마스터에 nc는 되는데 ssl 접속 자체가  제대로 안된다면? **
	- Bastion 서버의 /etc/ssh/sshd_config 파일에서 다음 확인 필요:
		AllowTcpForwarding yes
		PermitTunnel yes
		GatewayPorts yes
		(AllowTcpForwarding이 no일 경우 포트포워딩 자체가 불가능합니다.)
	- 수정 후 SSH 재시작:
		명령어 : sudo systemctl restart sshd

3. Bastion 연결명령어 저장해서 쓰면 편하다.
		명령어 : ssh -v -N -i ./kei-test-bastion-vm_key.pem -L 6443:10.0.2.4:6443 laonpeople@52.231.103.36
		(-v 옵션은 디버그 찍는 용도인데, 이걸 해놔야 명령어를 .sh파일로 실행해도 살아잇다. 명령어 후 오픈렌즈 켜서 작업.
			다 끝나면 터미널에 로그 맨 아래가서 ctrl + c 누르면 명령어 완전 종료  - 디버그 안찍으면 쉘 실행하고 끝이고, 종료 작업을
			할 수 없음. 그럼 또 터미널에서 명령어 : lsof -i :6443 해서 ssh 리슨하는 애들 다 죽여야 함)마스터 노드에서 파일 권한 임시 변경


---------------------------------------------------------------------------------------------


** 내 로컬의 UTM 프로그램으로 만든 가상머신에서 k8s 클러스터 접속 **


**내 pc의 virtual box 등으로 만든 가상머신 k8s를 내 로컬 pc에서 접속하기**

먼저 마스터노드에 있는 config파일을 내 로컬 pc로 복사한다.
	scp <user>@<마스터 노드IP>:/etc/kubernetes/admin.conf ~/kubeconfig
	# 로그인 비밀번호 입력
	- 만약 복사 중에 'scp: /etc/kubernetes/admin.conf: Permission denied' 이런 에러가 뜬다면 파일의 소유권 권한 문제!
		- 마스터 노드에서 파일 권한 임시 변경 : sudo cp /etc/kubernetes/admin.conf /home/<user>/admin.conf
						sudo chown user:user /home/<user>/admin.conf (etc에 있는 conf파일을 사용자 홈 디렉토리에 복사해서 권한 변경 후, 이 파일을 로컬에 복사)

2. 가상머신의 네트워크(k8s)와 내 로컬은 다른 네트환경 이기 때문에 포트포워딩 등 맞는 설정을 해야 한다.
	- 먼저는 마스터 노드의 /etc/kubernetes/manifests/kube-apiserver.yaml 에 - --bind-address=0.0.0.0 를 확인
	- 

